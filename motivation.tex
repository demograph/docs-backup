\section{Motivation}

{\it I want to maximize my asymptotic impact on collective wellbeing}.

In my view, this entails that for all the possible actions I have at my disposal at any point in time, I seek to identify and execute those that maximize collective-wellbeing in the long run.
âˆ«
When given a choice between something that will clearly help only in the short run or something will help us in the long run, I will choose the latter. However, when the difference in long-term impact is not clear, I will choose the one that has clearer short-term impact.

When given a choice to contribute a lot to the well-being of a small group or a little to a significant portion of the world, I will choose the latter. However, the former may still be sensible if helping the small group effectively contributes to collective-wellbeing in the long run.

When given the choice to provide precise answers to the questions raised by the above challenge, or just satisfying answers, I will choose the latter.

The challenge above clearly raise many questions, and many of those have already been studied extensively by smart and dedicated people. My asymptotic impact is unlikely maximized by trying to improve on answers that are already of considerable quality. Instead, I will simply handwave my way through what I believe to be acceptable answers, to identify something that best satisfies the above constraints. Much of what is below is therefore vague, and appeals more to intuition than to disciplined philosophy or scientific method, even though it feeds from it. We will however touch upon the fact that such shortcuts are an unfortunate necessity to fulfill the claimed desire, and our conclusion hopefully addresses a path to improving on that situation.

\section{Collective wellbeing}

What is required to maximize collective wellbeing? To put it simply, collective wellbeing depends on the subjective wellbeing of all individuals and the balance therein. To illustrate, let us first consider what subjective wellbeing means on the individual level.

Subjective wellbeing is a multifaceted concept. Ones SWB is influenced by genetic dispositions, situations and circumstances, income, social status and relationships. Other influences include ones nations economic climate, rule of law, social welfare policies, corruption and income inequality. How much each of these finally contributes to ones SWB is in the end very individual, even if we can identify cultural dispositions \cite{Tay2016}. And although we can recognize somewhat of Maslov's pyramid in that certain desires may obtain higher priority than others, we can also see that each need shows diminishing marginal utility which advocates for a balanced investment in all needs \cite{Tay2011}. In short, SWB is complex, but what matters is that {\it the subject itself has the most accurate access to his/her SWB.}

How does individual SWB relate to collective SWB? There is a strong argument to be made that balanced SWB is the ideal candidate for a definition of collective SWB, even more so when considering the long run. Increased SWB in our surroundings contributes directly because the wellbeing of others affects us positively in all our social interactions. Increased SWB in our surroundings also contributes indirectly because people with high SWB tend to perform better, leading to an improvement of ones surroundings. Finally, the diminishing marginal utility of investing in needs means that it is on a collective scale more efficient to invest in those that are not well off than in those that are already well off.

\section{Rationality}

Rationality is the key to obtain SWB. To think otherwise means having a different understanding of rationality. That is plausible as there are many attempts to formally define it, most notably in philosophy, psychology and economics. Before we proceed on why rationaliy is key to achieving SWB, let us settle on a shared definition.

Broadly, approaches to define rationality can be separated into two extremes; the descriptive and the prescriptive ones. Prescriptive accounts, such as rational choice theory \cite{Hands2015}, are concerned with being normative. They propose mathematically rigorous frameworks to compute ideal outcomes and suggest that agents must follow these rules in order to be considered rational. The trouble with prescriptive accounts is that they work elegantly and precise within their presupposed model, but that model often fails to apply in actual situations. Descriptive accounts, such as bounded rationality \cite{Simon1955}, are concerned with being realistic. They recognize the complexity of real situations and the limitation of an agents' reasoning faculties and other resources. The trouble with descriptive accounts is that they have no normative power.

These extremes have been long recognized and attempts are being made to bridge the gap, within disciplines \cite{Luce1994} and across \cite{Mcfall2015}, which is yet another complication in finding a proper working definition of rationality. One particular contribution I like in this regard is Max Alberts' \cite{Albert2009} convincing case for a philosophy of critical rationality. One of the central arguments captures what I consider a quintessential property of rationality, namely self-recommendation.

\begin{quote}
    A comprehensive conception of rationality should recommend itself: it should be rational to be rational
\end{quote}

Max defines three rules for rational belief formation.

\begin{enumerate}
    \item It is rational to believe the deductive consequences of rational beliefs
    \item It is rational to believe what one observes (observational beliefs), at least under certain circumstances
    \item It is rational to believe a hypothesis if it has so far withstood serious criticism better than its competitors
\end{enumerate}

The combination of these rules make up critical rationality. Max lists some other viable candidates for a definition of rationality and criticizes their viability. And as long as critical rationality stands up to criticism better than the alternatives, it is also self-recommending.

The strength of this ruleset is that it promotes satisficing, which roughly means maximization capped by contextual constraints. As long as critical rationality holds as the leading definition for rationality, any particularly interesting normative rules would be deductions from beliefs that are seriously criticized, and have survived. This could include 
Criticial rationality thus forms a minimal framework of rules that, when fed with observations, can be extended with new deducted rules and reject earlier rules that do not survive criticism.

For the sake of my earlier statement "Rationality is the key to obtain SWB"; I am assuming that humans attempt to function as SWB-maximizers. An SWB-maximizer is ideally rational, 


There is a long lineage of philosophy of rationality that treats rationality, on a high level, as an alignment between desires, beliefs and plans or actions; Bratman is one champion in this philosophy \cite{Bratman1987}. Desires have a similar role as utility or preferences, which occur more frequently in economist accounts. Beliefs are those subjective mental attitudes that form ones model of the world. Beliefs are not required to be true or immutable. Roughly speaking, desires form the reason to act, beliefs ought to decide how to act. The big question is how to establish whether the outcome (an action, or intent or plan to act) of a decision-making process is rational.

I am not concerned with providing the conditions under which the processing of these particular inputs have lead to the optimal outcome, in a rational manner.

Desires are some configuration that defines what it is for an individual to be well. Utility is a function that takes desires and some hypothetical change and assigns the change a value that reflects the value for this change in light of the desires. Subjective wellbeing is the extent to which the current state of affairs is in line with ones desires.

Bratmans Desires + Beliefs = Intention, where `+` is a rational combinator. Inputs are delta-streams, output is a delta-stream. Quality of the delta-stream is how close it approximates the output of an optimal rationality operator that is similarly bounded. The big variable in the equation is beliefs.

Rationality is often considered to be concerned with finding or doing what is best. It therefore has a binary quality, either you did the best thing or you didn't. Obviously, there are many ways in which it is non-binary as well. One can be closer or further away from the best option even if one failed to find the best option. When given successive opportunities for rational behavior, one can have a particular rate of success. When speaking of 'improving rationality', I refer to the degrees of freedom that we have here.

\subsection{Unconscious rationalism}

Usually, when speaking of rationality, there is an implication of active mental reasoning processes of which one is aware. However, it is well known that there is much under the cover when it comes to our minds. Only certain stimuli make it to our awareness, which is perceived to be a tight coupling between how we choose to focus and the environment. We at least appear to choose to focus on certain things, but evidently it is also the environment that forces us to shift our attention. When working towards an understanding of rationality, one cannot ignore that which is under the cover of awareness, nor do I want to. We can extend our simplistic model of beliefs, desires and intention to corresponding ones in our unconscious. The reasoning process that mediates between these three structures can be partially or wholly unconscious and still be rational, as far as I am concerned. The fact that some of it takes place in our awareness, or whether we exercise mental control over our cognitive abilities is irrelevant to the question of whether the mapping of beliefs and desires to intentions is of rational high quality.

One might think differently for the following reason. When performing mathematics, we cannot just give a good outcome to a puzzle, we have to show that we used the right method. This rigour is of high value because it allows one to repeat the success of deriving the right outcome for any given question. However, nobody continues to work rigorously from axioms, following explicitly every minimal inference rule, until the answer is logically derived. We develop intuitions for certain compositions of inferences, they become second nature, and as such stop to pass our awareness when doing mathematical judo. Of course, when publishing a paper on a theorem, it is important to show that the logic is sound (and even then, often shortcuts are made, because one communicates typically to peers with similar mental states). However, that doesn't mean that our reasoning wasn't sound at the moment we followed our mathematical instincts and these lead to the right answers.

\subsection{Rationalism in time}

Ones set of beliefs and desires isn't fixed in time. Clealy, beliefs develop as we gain experience. For desires one could argue that at least a portion is tied to some bit of you that is immutable. This is a somewhat romantic idea, but I don't believe in an immutable persona. A spike through your brain will have obvious impact on your person, if you survive it, and less dramatically, there is always wear and tear on your brain, or any part of your body. We can however differentiate between desires that are deeper in your unconscious and those that are more on the surface. It seems to me that those deeper in your unconscious are the ones that are more stable, more fundamental to your being than others. They are tied to your genetic dispositions and how that and the environment developed your brain; These desires are tied to the larger architecture of your brain which is more resilient to change than a few neurons in particular.

We develop our desires along more lines however. First off, we become more aware of them over time, by which I mean that we obtain more clear, explicit representations of them. We might start out by a desire to obtain our parents approval, but before lies an enormous space of options that might lead to that approval. As one might experiment with several options, probably failing most, we find that some work, but also that we may have preferred some of them ourselves. If so, this is the manifestation of a desire that your body is signalling to you is getting satisfied. To make it less abstract, we might try to get our parents approval through doing well in sports and stamp collection. From our limited child perspectives, this both might lead to the approval response we seek, for different reasons; likely pride for you doing well in a championship and being relaxed due to not bein an annoying kid. As we try those things, we exercise parts of our brains and our brain rewards us. Your brain might have the architecture that particularly rewards you for the physical exercise you get, or it might be the kind of brain whose neurotransmitters 'fire happily away' when observing well-orderedness. Depending on the particular outcome, you divide your time between the activities. You may develop awareness such as "I like sports", "I like this sport", "I like regularity" or "I like stamp collection". These are more concrete desires that manifest themselves, perhaps even to your awareness, but are really a relation between a more fundamental desire, a belief and a more concrete desire. The concrete desire is supported by the fundamental desire and the belief that satisfying the concrete desire is a means to satisfy the more fundamental one.

I realize that I'm stretchig the notions of desire and belief beyond what is common parlance, but it is mostly meant to be illustrative. It is quite acceptable to say that "I want to finish university", which signals a desire, but we all know that is not a fundamental one. It really is just a concretization of many, increasingly more fundamental desires, mediated by beliefs that become increasingly less explicit and available to our awareness. At some level, comparing the forces that mediate the belief relationships to beliefs might be too much of a stretch, but I'm mostly interested in the cases where it isn't too much of a stretch, and I think it should be acceptable at this point that those beliefs may be quite deep in your unconscious without being irrational.

\section{Collective Rationality}

If rationality is the extent to which one succeeds in the timely actions / formation of plans and intentions that ones beliefs predict to maximize the satisfaction of ones desires over time, then what is collective rationality?

Is a collective something more than its constituents? It's a bad question because it doesn't allow clear answers.

To get an initial idea of what collective rationality is and isn't, let's look at a few comparitive examples.

- It is collectively less rational to make war than make peace, in any real situation.
- It is collectively less rational to pollute the only living planet you require into extinction, than to enforce policies or mechanisms that stop this from happening.

I have not made the effort to be particularly careful about my formulation, and it leaves plenty of nitpicking space. Nonetheless, I think the examples are self-evident (1) all individuals prefer the left over the right and (2) I think it is common knowledge that these examples are self-evident, we know of each other that we know this, ad infinitum. This makes it collectively irrational that we end up in these states. This collectively rational failure doesn't have to be due to the rational failure of some individuals. Very likely, it is caused by people that act rational enough on an individual level, but work in a system where the individual rationalities don't add up to collective ones. The fact that some desires are polar opposites of one another may be causally related, but doesn't determine the outcome; there are plenty of ways to work towards outcomes that are more desirable to all individuals than the massively destructive ones. And even if one would blame particular individuals for the state we ended up in, it is still the system that we collectively formed that enabled them to get us there.

We established that collective rationality does depend on the extent to which its individuals are rational, but that the more important factor is the system in which these individuals are situated. So what is this system, and how should it change to have us move from the collectively less rational to the more rational outcome?

Here I would like to reference Lawrence Lessig's "Code is Law". The system is made up of 

Architecture
that which is possible, given real constraints in life such as physical laws. Also includes the (generative) tools that we built that level up our capabilities

Norms
That which is socially permitted/controlled, violation of which will have social repercussions if detected.

Laws
That which is permitted by rules we explicitly formulated and through which usually forms of enforcements exist. There is an expenditure to enforce those rules that is balanced by the repercussions of having the rules broken. Evolution of law has a hard time keeping up with the pace with which architecture (our capability to act) develops.

TODO: Lawrence claims in his book that (source) code is law, but I would claim it is, or can be both architecture and law.

Of these three, architecture interests me the most for its generative nature (Jonathan Zittrain).

More views on systems:

- markets, governments
- stigmergic development
- shared and conflicting desires (market goods) and belief (criticized pool of beliefs, McMahon)

Stigmergy